{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understand the CRF code and the feature_mapper code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys; sys.path.append(\"../../../\")\n",
    "from lxmls import DATA_PATH\n",
    "import lxmls\n",
    "import lxmls.sequences.crf_online as crfo\n",
    "import lxmls.readers.pos_corpus as pcc\n",
    "import lxmls.sequences.id_feature as idfc\n",
    "import lxmls.sequences.extended_feature as exfc\n",
    "from lxmls.readers import pos_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data from the conll task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus = lxmls.readers.pos_corpus.PostagCorpus()\n",
    "\n",
    "train_seq = corpus.read_sequence_list_conll(DATA_PATH + \"/train-02-21.conll\", \n",
    "                                            max_sent_len=10, max_nr_sent=1000)\n",
    "\n",
    "test_seq = corpus.read_sequence_list_conll(DATA_PATH + \"/test-23.conll\", \n",
    "                                           max_sent_len=10, max_nr_sent=1000)\n",
    "\n",
    "dev_seq = corpus.read_sequence_list_conll(DATA_PATH + \"/dev-22.conll\", \n",
    "                                          max_sent_len=10, max_nr_sent=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"There are\", len(train_seq), \"examples in train_seq\")\n",
    "print(\"First example:\", train_seq[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature generation\n",
    "\n",
    "Given a dataset, in order to build the features\n",
    "\n",
    "- An instance from **`lxmls.sequences.id_feature.IDFeatures(train_data)`** must be instanciated. We will call `feature_mapper` this instanciated object.\n",
    "- Then **`feature_mapper.build_features()`** must be executed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Building features\n",
    "feature_mapper = idfc.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### About feature_mappers\n",
    "A ```feature_mapper``` will contain the following attributes:\n",
    "\n",
    "- the dataset in ```.dataset```\n",
    "    - if we instantiate the feature mapper with a dataset X then ```feature_mapper.dataset```will be a copy of X\n",
    "\n",
    "\n",
    "- a dictionary of features in ```.feature_dict```\n",
    "    - this dictionary will default to ```{}```. \n",
    "    - In order to build the features the feature mapper must call ```.build_features()``` function.\n",
    "    \n",
    "    \n",
    "- a list of features in ```.feature_list```\n",
    "    - this list will default to ```[]```. \n",
    "    - In order to build the list of features the feature mapper must call ```.build_features()``` function.\n",
    "\n",
    "A ```feature_mapper``` will contain the method \n",
    "\n",
    "- A method to generate features, ```.build_features```\n",
    "    - this method will create features using the ```.dataset``.\n",
    "    - This method will also fill ```.feature_dict``` and ```.feature_list``\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(feature_mapper.feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Let's see the features for the first training example\n",
    "feature_mapper.feature_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## The previous features can be classified into:\n",
    "\n",
    "print(\"\\nInitial features:\",     feature_mapper.feature_list[0][0])\n",
    "print(\"\\nTransition features:\",  feature_mapper.feature_list[0][1])\n",
    "print(\"\\nFinal features:\",       feature_mapper.feature_list[0][2])\n",
    "print(\"\\nEmission features:\",    feature_mapper.feature_list[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An observation on the features for a given example\n",
    "\n",
    "All features for all the training examples in are saved in `train_seq` will be saved in ``feature_mapper.feature_list``.\n",
    "\n",
    "- If `feature_mapper.feature_list[m]` is our feature vector for training example `m`... why it's not a vector?\n",
    "\n",
    "    - Good point! In order to make the algorithm fast, the code is written using dicts, so if we access only a few positions from the dict and compute substractions it will be much faster than computing the substraction of two huge weight vectors. Notice that there are `len(feature_mapper.feature_dict)` features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(train_seq), len(feature_mapper.feature_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codification of the features\n",
    "\n",
    "\n",
    "Features are identifyed by **init_tag:**, **prev_tag:**,  **final_prev_tag:**, **id:**\n",
    "\n",
    "- **init_tag:** when they are Initial features\n",
    "    - Example: **``init_tag:noun``** is an initial feature that describes that the first word is a noun\n",
    "    \n",
    "    \n",
    "- **prev_tag:** when they are transition features\n",
    "    - Example: **``prev_tag:noun::noun``** is an transition feature that describes that the previous word was\n",
    "      a noun and the current word is a noun.\n",
    "    - Example: **``prev_tag:noun:.``** is an transition feature that describes that the previous word was\n",
    "      a noun and the current word is a `.` (this is usually foud as the last transition feature since most phrases will end up with a dot)\n",
    "      \n",
    "\n",
    "\n",
    "- **final_prev_tag:** when they are final features\n",
    "    - Example: **``final_prev_tag:.``** is a final feature stating that the last \"word\" in the sentence was a dot.\n",
    "\n",
    "\n",
    "- **id:** when they are emission features\n",
    "    - Example: **``id:plays::verb``** is an emission feature, describing that the current word is plays and the current hidden state is a verb.\n",
    "    - Example: **``id:Feb.::noun``** is an emission feature, describing that the current word is \"Feb.\" and the current hidden state is a noun.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inv_feature_dict = {word: pos for pos, word in feature_mapper.feature_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feature_mapper.feature_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[inv_feature_dict[x[0]] for x in feature_mapper.feature_list[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[inv_feature_dict[x[0]] for x in feature_mapper.feature_list[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[inv_feature_dict[x[0]] for x in feature_mapper.feature_list[0][2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(train_seq.x_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train a crf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Train crf\n",
    "crf_online = crfo.CRFOnline(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "crf_online.num_epochs = 20\n",
    "crf_online.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## You will receive feedback when each epoch is finished,\n",
    "## note that running the 20 epochs might take a while. After training is done,\n",
    "## evaluate the learned model on the training, development and test sets.\n",
    "\n",
    "pred_train = crf_online.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = crf_online.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = crf_online.viterbi_decode_corpus(test_seq)\n",
    "\n",
    "eval_train = crf_online.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = crf_online.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = crf_online.evaluate_corpus(test_seq, pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(\"CRF - ID Features Accuracy Train: %.3f Dev: %.3f Test: %.3f\" \\\n",
    "       %(eval_train,eval_dev, eval_test))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
