{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise we will use the Amazon sentiment analysis data (Blitzer et al., 2007), where the goal is to classify text documents as expressing a positive or negative sentiment (i.e., a classification problem with two classes). We are going to focus on book reviews. To load the data, type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxmls.readers.sentiment_reader as srs\n",
    "scr = srs.SentimentCorpus(\"books\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will load the data in a bag-of-words representation where rare words (occurring less than 5 times in the training data) are removed.\n",
    "\n",
    "1. Implement the Naive Bayes algorithm. Open the file `multinomial_naive_bayes.py`,  which is inside the classifiers folder. In the MultinomialNaiveBayes class you will find the train method. We have already placed some code in that file to help you get started.\n",
    "    \n",
    "2. After implementing, run Naive Bayes with the multinomial model on the Amazon dataset (sentiment classification) and report results both for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.multinomial_naive_bayes as mnbb\n",
    "mnb = mnbb.MultinomialNaiveBayes()\n",
    "params_nb_sc = mnb.train(scr.train_X,scr.train_y)\n",
    "y_pred_train = mnb.test(scr.train_X,params_nb_sc)\n",
    "acc_train = mnb.evaluate(scr.train_y, y_pred_train)\n",
    "y_pred_test = mnb.test(scr.test_X,params_nb_sc)\n",
    "acc_test = mnb.evaluate(scr.test_y, y_pred_test)\n",
    "print(\"Multinomial Naive Bayes Amazon Sentiment Accuracy train: %f test: %f\"%(acc_train,acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that words that were not observed at training time cause problems at testtime. Why? To  solve this problem, apply a simple add-one smoothing technique:  replace the expression in Eq. 1.9 for the estimation of the conditional probabilities by\n",
    "    \n",
    "${\\hat P}(w_j|c_k) = \\frac{1+\\sum_ {m \\in \\mathcal{I}_k} n_j(x^m)}{J + \\sum_{i=1}^J \\sum_ {m\\in \\mathcal{I}_k} n_i(x^m)}.$\n",
    "\n",
    "where $J$ is the number of distinct words. This is a widely used smoothing strategy which has a Bayesian interpretation: it corresponds to choosing a uniform prior for the word distribution on both classes, and to replace the maximum likelihood criterion by a maximum a posteriori approach. This is a form of regularization, preventing the model from overfitting on the training data. See e.g. Manning and Sch√ºtze (1999); Manning et al. (2008) for more information. Report the new accuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We provide an implementation of the perceptron algorithm in the class Perceptron\n",
    "(file `perceptron.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following commands to generate a simple dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import lxmls.readers.simple_data_set as sds\n",
    "sd = sds.SimpleDataSet(\n",
    "    nr_examples=100,\n",
    "    g1=[[-1,-1],1], \n",
    "    g2=[[1,1],1], \n",
    "    balance=0.5,\n",
    "    split=[0.5,0,0.5]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the perceptron algorithm on the simple dataset previously generated and report its train and test set accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.perceptron as percc\n",
    "perc = percc.Perceptron()\n",
    "params_perc_sd = perc.train(sd.train_X,sd.train_y)\n",
    "y_pred_train = perc.test(sd.train_X,params_perc_sd)\n",
    "acc_train = perc.evaluate(sd.train_y, y_pred_train)\n",
    "y_pred_test = perc.test(sd.test_X,params_perc_sd)\n",
    "acc_test = perc.evaluate(sd.test_y, y_pred_test)\n",
    "print(\"Perceptron Simple Dataset Accuracy train: %f test: %f\"%(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axis = sd.plot_data(\"osx\")\n",
    "fig, axis = sd.add_line(fig, axis, params_perc_sd, \"Perceptron\", \"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the code to save the intermediate weight vectors, and plot them every five iterations. What do you observe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.3\n",
    "We provide an implementation of the MIRA algorithm. Compare it with the perceptron for various values of $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.mira as mirac\n",
    "mira = mirac.Mira()\n",
    "mira.regularizer = 1.0 # This is lambda\n",
    "params_mira_sd = mira.train(sd.train_X,sd.train_y)\n",
    "y_pred_train = mira.test(sd.train_X,params_mira_sd)\n",
    "acc_train = mira.evaluate(sd.train_y, y_pred_train)\n",
    "y_pred_test = mira.test(sd.test_X,params_mira_sd)\n",
    "acc_test = mira.evaluate(sd.test_y, y_pred_test)\n",
    "print(\"Mira Simple Dataset Accuracy train: %f test: %f\"%(acc_train, acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results achieved and separating hyperplanes found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axis = sd.add_line(fig, axis, params_mira_sd, \"Mira\",\"green\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.4\n",
    "We provide an implementation of the L-BFGS algorithm for training maximum entropy models in the class MaxEnt batch, as well as an implementation of the SGD algorithm in the class `MaxEnt online`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.max_ent_batch as mebc\n",
    "me_lbfgs = mebc.MaxEntBatch()\n",
    "me_lbfgs.regularizer = 1.0\n",
    "params_meb_sd = me_lbfgs.train(sd.train_X,sd.train_y)\n",
    "y_pred_train = me_lbfgs.test(sd.train_X,params_meb_sd)\n",
    "acc_train = me_lbfgs.evaluate(sd.train_y, y_pred_train)\n",
    "y_pred_test = me_lbfgs.test(sd.test_X,params_meb_sd)\n",
    "acc_test = me_lbfgs.evaluate(sd.test_y, y_pred_test)\n",
    "print(\n",
    "    \"Max-Ent batch Simple Dataset Accuracy train: %f test: %f\" % \n",
    "    (acc_train,acc_test)\n",
    ")\n",
    "fig, axis = sd.add_line(fig, axis, params_meb_sd, \"Max-Ent-Batch\",\"orange\")\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train a maximum entropy model using L-BFGS, on the Amazon dataset (try different values of $\\lambda$) and report training and test set accuracy. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_meb_sc = me_lbfgs.train(scr.train_X,scr.train_y)\n",
    "y_pred_train = me_lbfgs.test(scr.train_X,params_meb_sc)\n",
    "acc_train = me_lbfgs.evaluate(scr.train_y, y_pred_train)\n",
    "y_pred_test = me_lbfgs.test(scr.test_X,params_meb_sc)\n",
    "acc_test = me_lbfgs.evaluate(scr.test_y, y_pred_test)\n",
    "print(\n",
    "    \"Max-Ent Batch Amazon Sentiment Accuracy train: %f test: %f\" % \n",
    "    (acc_train, acc_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, fix $\\lambda$ = 1.0 and train with SGD (you might try to adjust the initial step). Compare the objective values obtained during training with those obtained with L-BFGS. What do you observe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.max_ent_online as meoc\n",
    "me_sgd = meoc.MaxEntOnline()\n",
    "me_sgd.regularizer = 1.0\n",
    "params_meo_sc = me_sgd.train(scr.train_X,scr.train_y)\n",
    "y_pred_train = me_sgd.test(scr.train_X,params_meo_sc)\n",
    "acc_train = me_sgd.evaluate(scr.train_y, y_pred_train)\n",
    "y_pred_test = me_sgd.test(scr.test_X,params_meo_sc)\n",
    "acc_test = me_sgd.evaluate(scr.test_y, y_pred_test)\n",
    "print(\n",
    "    \"Max-Ent Online Amazon Sentiment Accuracy train: %f test: %f\" % \n",
    "    (acc_train, acc_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1.5\n",
    "Run the SVM primal algorithm. Then, repeat the MaxEnt exercise now using SVMs, for several values of $\\lambda$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lxmls.classifiers.svm as svmc\n",
    "svm = svmc.SVM()\n",
    "svm.regularizer = 1.0 # This is lambda\n",
    "params_svm_sd = svm.train(sd.train_X,sd.train_y)\n",
    "y_pred_train = svm.test(sd.train_X,params_svm_sd)\n",
    "acc_train = svm.evaluate(sd.train_y, y_pred_train)\n",
    "y_pred_test = svm.test(sd.test_X,params_svm_sd)\n",
    "acc_test = svm.evaluate(sd.test_y, y_pred_test)\n",
    "print(\"SVM Online Simple Dataset Accuracy train: {} test: {}\".format(acc_train,acc_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,axis = sd.add_line(fig,axis,params_svm_sd,\"SVM\",\"orange\")\n",
    "params_svm_sc = svm.train(scr.train_X,scr.train_y)\n",
    "y_pred_train = svm.test(scr.train_X,params_svm_sc)\n",
    "acc_train = svm.evaluate(scr.train_y, y_pred_train)\n",
    "y_pred_test = svm.test(scr.test_X,params_svm_sc)\n",
    "acc_test = svm.evaluate(scr.test_y, y_pred_test)\n",
    "print(\"SVM Online Amazon Sentiment Accuracy train: {} test: {}\".format(acc_train,acc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the results achieved and separating hyperplanes found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axis = sd.add_line(fig, axis, params_svm_sd, \"SVM\", \"yellow\")\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "git": {
   "suppress_outputs": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}